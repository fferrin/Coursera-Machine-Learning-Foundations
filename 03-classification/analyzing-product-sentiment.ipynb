'''Fire up graphlab create'''

import graphlab

# Set product key on this computer. After running this cell, you will not need 
# to re-enter your product key. 
graphlab.product_key.set_product_key('product key')

# Limit number of worker processes. This preserves system memory, which prevents
hosted notebooks from crashing.
graphlab.set_runtime_config('GRAPHLAB_DEFAULT_NUM_PYLAMBDA_WORKERS', 4)


'''Read some product review data'''
products = graphlab.SFrame('amazon_baby.gl/')


'''Let's explore this data together'''
products.head()


'''Build the word count vector for each review'''
products['word_count'] = graphlab.text_analytics.count_words(products['review'])
products.head()

graphlab.canvas.set_target('ipynb')
products['name'].show()


'''
Examining the reviews for most-sold product: "Vulli Sophie the Giraffe Teether"
'''
giraffe_reviews = products[products['name'] == 'Vulli Sophie the Giraffe 
                           Teether']
giraffe_reviews['rating'].show(view='Categorical')


'''Build a sentiment classifier'''
products['rating'].show(view='Categorical')


'''Define what's a positive and a negative sentiment'''
# ignore all 3* reviews
products = products[products['rating'] != 3]
# positive sentiment = 4* or 5* reviews
products['sentiment'] = products['rating'] >=4
products.head()


'''Let's train the sentiment classifier'''
train_data, test_data = products.random_split(0.8, seed=0)
sentiment_model = graphlab.logistic_classifier.create(train_data,
                                                      target='sentiment',
                                                      features=['word_count'],
                                                      validation_set=test_data)


'''Evaluate the sentiment model'''
sentiment_model.evaluate(test_data, metric='roc_curve')
sentiment_model.show(view='Evaluation')


'''Applying the learned model to understand sentiment for Giraffe'''
giraffe_reviews['predicted_sentiment'] = sentiment_model.predict(
                                            giraffe_reviews, 
                                            output_type='probability')
giraffe_reviews.head()


'''Sort the reviews based on the predicted sentiment and explore'''
giraffe_reviews = giraffe_reviews.sort('predicted_sentiment', ascending=False)
giraffe_reviews.head()


'''Most positive reviews for the giraffe'''
giraffe_reviews[0]['review']
giraffe_reviews[1]['review']


'''Show most negative reviews for giraffe'''
giraffe_reviews[-1]['review']
giraffe_reviews[-2]['review']


'''QUESTIONS'''
# 1. Out of the 11 words in selected_words, which one is most used in the 
# reviews in the dataset?
# 2. Out of the 11 words in selected_words, which one is least used in the 
# reviews in the dataset?
def awesome_count(d):
    if 'awesome' not in d:
        return 0
    else:
        return d['awesome']

products['awesome'] = products['word_count'].apply(awesome_count)
selected_words = ['awesome', 'great', 'fantastic', 'amazing', 'love', 
                  'horrible', 'bad', 'terrible', 'awful', 'wow', 'hate']

for word in selected_words:
    products[word] = products['word_count']
                        .apply(lambda x: 0 if not word in x else x[word])

for word in selected_words:
    print word, products[word].sum()

# 3. Out of the 11 words in selected_words, which one got the most positive 
# weight in the selected_words_model?
# 4. Out of the 11 words in selected_words, which one got the most negative 
# weight in the selected_words_model?
train_data_selected, test_data_selected = products.random_split(0.8, seed=0)
selected_words_model = graphlab.logistic_classifier
                            .create(train_data_selected,
                                    target='sentiment',
                                    features=selected_words,
                                    validation_set=test_data_selected)

selected_words_model['coefficients'].sort('value').print_rows(num_rows=13)

# 5. Which of the following ranges contains the accuracy of the 
# selected_words_model on the test_data?
selected_words_model.evaluate(test_data_selected)

# 6. Which of the following ranges contains the accuracy of the sentiment_model 
# in the IPython Notebook from lecture on the test_data?
sentiment_model.evaluate(test_data)

# 7. Which of the following ranges contains the accuracy of the majority class 
# classifier, which simply predicts the majority class on the test_data?
print "Majority class (positive_sentiment/total_count):", 
      (85710+26573)*1.0/(85710+26573+12103+9062) 

# 8. How do you compare the different learned models with the baseline approach 
# where we are just predicting the majority class?
# The model learned using all words performed much better than the other two. 
# The other two approaches performed about the same.

# 9. Which of the following ranges contains the ‘predicted_sentiment’ for the 
# most positive review for ‘Baby Trend Diaper Champ’, according to the 
# sentiment_model from the IPython Notebook from lecture?
baby_trend = products[products['name'] == 'Baby Trend Diaper Champ']
baby_trend['predicted_sentiment'] = sentiment_model
                                        .predict(baby_trend, 
                                                 output_type='probability')

baby_trend.sort('predicted_sentiment', ascending=False)

# 10. Consider the most positive review for ‘Baby Trend Diaper Champ’ according 
# to the sentiment_model from the IPython Notebook from lecture. Which of the 
# following ranges contains the predicted_sentiment for this review, if we use 
# the selected_words_model to analyze it?
baby_trend['predicted_sentiment_selected'] = selected_words_model
                                            .predict(baby_trend, 
                                                     output_type='probability')
baby_trend.sort('predicted_sentiment', ascending=False)

# 11. Why is the value of the predicted_sentiment for the most positive review 
# found using the sentiment_model much more positive than the value predicted 
# using the selected_words_model?
# None of the selected_words appeared in the text of this review.